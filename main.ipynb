{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-22T10:54:15.442015Z",
     "iopub.status.busy": "2025-04-22T10:54:15.441439Z",
     "iopub.status.idle": "2025-04-22T10:54:19.519224Z",
     "shell.execute_reply": "2025-04-22T10:54:19.518209Z",
     "shell.execute_reply.started": "2025-04-22T10:54:15.441986Z"
    },
    "id": "zFiO79auUY4S",
    "outputId": "3d33e0e0-2d08-4b67-b35f-31209bf25f19"
   },
   "outputs": [],
   "source": [
    "%pip install kagglehub google-genai pandas numpy matplotlib seaborn scikit-learn tensorflow pillow gradio xgboost lightgbm catboost category_encoders plotly h5py -q\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core libraries\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import io\n",
    "import base64\n",
    "import urllib.request\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from collections import Counter\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Image processing\n",
    "from PIL import Image\n",
    "\n",
    "# Google Gemini\n",
    "from google import genai\n",
    "\n",
    "# TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import h5py\n",
    "\n",
    "# Scikit-learn - model selection & preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Scikit-learn - classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Scikit-learn - regressors\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Scikit-learn - metrics\n",
    "from sklearn.metrics import (classification_report, accuracy_score, r2_score, \n",
    "                              mean_squared_error, mean_absolute_error, \n",
    "                              confusion_matrix, hamming_loss, f1_score)\n",
    "\n",
    "# Advanced ML libraries\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb_lib\n",
    "from catboost import CatBoostRegressor\n",
    "import category_encoders as ce\n",
    "\n",
    "# Gradio UI\n",
    "import gradio as gr\n",
    "\n",
    "print(\"âœ“ All packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T11:02:08.278576Z",
     "iopub.status.busy": "2025-04-22T11:02:08.277841Z",
     "iopub.status.idle": "2025-04-22T11:02:08.282224Z",
     "shell.execute_reply": "2025-04-22T11:02:08.281474Z",
     "shell.execute_reply.started": "2025-04-22T11:02:08.278549Z"
    },
    "id": "mg77BtiUUY4T"
   },
   "outputs": [],
   "source": [
    "DATASET_ROOT = os.path.join(os.getcwd(), \"dataset\")\n",
    "os.makedirs(DATASET_ROOT, exist_ok=True)\n",
    "\n",
    "GITHUB_BASE_URL = \"https://raw.githubusercontent.com/george-bobby/crop-prediction/main/dataset\"\n",
    "\n",
    "def ensure_github_dataset(github_path: str):\n",
    "    \"\"\"\n",
    "    Download dataset from GitHub\n",
    "    github_path: path like 'owner/repo' which maps to dataset/owner/repo\n",
    "    \"\"\"\n",
    "    if \"/\" not in github_path:\n",
    "        raise ValueError(\"github_path must be in the form 'owner/repo'\")\n",
    "    owner, repo = github_path.split(\"/\", 1)\n",
    "    target_dir = os.path.join(DATASET_ROOT, owner, repo)\n",
    "    \n",
    "    # Check if dataset already exists locally\n",
    "    if os.path.exists(target_dir) and any(os.scandir(target_dir)):\n",
    "        print(f\"âœ“ Using cached dataset: {target_dir}\")\n",
    "        return target_dir\n",
    "    \n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    \n",
    "    # List of common file extensions to download\n",
    "    file_extensions = ['.csv', '.xlsx', '.xls', '.json', '.txt']\n",
    "    \n",
    "    # Try to download files from the GitHub repository structure\n",
    "    github_url = f\"{GITHUB_BASE_URL}/{owner}/{repo}\"\n",
    "    \n",
    "    # Define specific files to download for each dataset\n",
    "    dataset_files = {\n",
    "        \"hiteshsoneji/historical-weather-data-for-indian-cities\": [\n",
    "            \"bengaluru.csv\", \"bombay.csv\", \"delhi.csv\", \"hyderabad.csv\", \n",
    "            \"jaipur.csv\", \"kanpur.csv\", \"nagpur.csv\", \"pune.csv\"\n",
    "        ],\n",
    "        \"atharvaingle/crop-recommendation-dataset\": [\"Crop_recommendation.csv\"],\n",
    "        # \"tushar5harma/plant-village-dataset-updated\": [],  # COMMENTED OUT: Using pre-trained model instead\n",
    "        \"anshtanwar/current-daily-price-of-various-commodities-india\": [\"Price_Agriculture_commodities_Week.csv\"],\n",
    "        \"kaustubhgupta/crop-production-in-india\": [\"crop_yield.csv\"],\n",
    "        \"asishpandey/crop-production-in-india\": [\n",
    "            \"Crop_production.csv\", \"crop_yield.csv\", \"Data_after_rainfall.csv\",\n",
    "            \"Fertilizer.csv\", \"Final_Dataset_after_temperature.csv\", \n",
    "            \"final_rainfall.csv\", \"final_temperature.csv\", \n",
    "            \"rainfall_validation.csv\", \"temperature.csv\"\n",
    "        ],\n",
    "        \"akshatgupta7/crop-yield-in-indian-states-dataset\": [\"crop_yield.csv\"]\n",
    "    }\n",
    "    \n",
    "    files_to_download = dataset_files.get(github_path, [])\n",
    "    \n",
    "    if not files_to_download:\n",
    "        print(f\"âš  Warning: No specific files defined for {github_path}. Skipping download.\")\n",
    "        return target_dir\n",
    "    \n",
    "    print(f\"Downloading {len(files_to_download)} files from {github_url}...\")\n",
    "    \n",
    "    for filename in files_to_download:\n",
    "        url = f\"{github_url}/{filename}\"\n",
    "        local_path = os.path.join(target_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            print(f\"  Downloading {filename}...\", end=\" \")\n",
    "            urllib.request.urlretrieve(url, local_path)\n",
    "            print(f\"âœ“\")\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— Failed: {str(e)}\")\n",
    "    \n",
    "    print(f\"âœ“ Dataset downloaded to: {target_dir}\\n\")\n",
    "    return target_dir\n",
    "\n",
    "# Download datasets from GitHub\n",
    "hiteshsoneji_historical_weather_data_for_indian_cities_path = ensure_github_dataset(\"hiteshsoneji/historical-weather-data-for-indian-cities\")\n",
    "atharvaingle_crop_recommendation_dataset_path = ensure_github_dataset(\"atharvaingle/crop-recommendation-dataset\")\n",
    "anshtanwar_current_daily_price_of_various_commodities_india_path = ensure_github_dataset(\"anshtanwar/current-daily-price-of-various-commodities-india\")\n",
    "kaustubhgupta_crop_production_in_india_path = ensure_github_dataset(\"kaustubhgupta/crop-production-in-india\")\n",
    "asishpandey_crop_production_in_india = ensure_github_dataset(\"asishpandey/crop-production-in-india\")\n",
    "tushar5harma_plant_village_dataset_updated_path = os.path.join(DATASET_ROOT, \"tushar5harma\", \"plant-village-dataset-updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = \"AIzaSyCfyGoWqbRu4cim4qxbNBili_4ExkLF7ps\"\n",
    "gemini_client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-22T11:02:41.699673Z",
     "iopub.status.busy": "2025-04-22T11:02:41.698973Z",
     "iopub.status.idle": "2025-04-22T11:04:42.295866Z",
     "shell.execute_reply": "2025-04-22T11:04:42.295149Z",
     "shell.execute_reply.started": "2025-04-22T11:02:41.699647Z"
    },
    "id": "xhrIx9BzUY4U",
    "outputId": "5b54606e-1d76-47a5-f8c3-93212750198c"
   },
   "outputs": [],
   "source": [
    "for root, _, files in os.walk(kaustubhgupta_crop_production_in_india_path):\n",
    "    if \"crop_production.csv\" in files:\n",
    "        crop_production_df = pd.read_csv(os.path.join(root, \"crop_production.csv\"))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "execution": {
     "iopub.execute_input": "2025-04-22T11:06:03.008891Z",
     "iopub.status.busy": "2025-04-22T11:06:03.008269Z",
     "iopub.status.idle": "2025-04-22T11:06:03.3453Z",
     "shell.execute_reply": "2025-04-22T11:06:03.344757Z",
     "shell.execute_reply.started": "2025-04-22T11:06:03.008867Z"
    },
    "id": "e3r8mndGUY4U",
    "outputId": "7cc19e67-3c2e-4d56-fb7b-095ff9e12357"
   },
   "outputs": [],
   "source": [
    "for root, _, files in os.walk(atharvaingle_crop_recommendation_dataset_path):\n",
    "    if \"Crop_recommendation.csv\" in files:\n",
    "        crop_recommendation_df = pd.read_csv(os.path.join(root, \"Crop_recommendation.csv\"))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T11:06:15.720712Z",
     "iopub.status.busy": "2025-04-22T11:06:15.720004Z",
     "iopub.status.idle": "2025-04-22T11:06:15.744407Z",
     "shell.execute_reply": "2025-04-22T11:06:15.743663Z",
     "shell.execute_reply.started": "2025-04-22T11:06:15.720685Z"
    },
    "id": "uFmwdq6nUY4V"
   },
   "outputs": [],
   "source": [
    "X = crop_recommendation_df.drop('label', axis=1)\n",
    "y = crop_recommendation_df['label']\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T11:06:44.089456Z",
     "iopub.status.busy": "2025-04-22T11:06:44.088747Z",
     "iopub.status.idle": "2025-04-22T11:06:44.143495Z",
     "shell.execute_reply": "2025-04-22T11:06:44.142858Z",
     "shell.execute_reply.started": "2025-04-22T11:06:44.089421Z"
    },
    "id": "c-aFIvSSUY4W"
   },
   "outputs": [],
   "source": [
    "for root, _, files in os.walk(anshtanwar_current_daily_price_of_various_commodities_india_path):\n",
    "    if \"Price_Agriculture_commodities_Week.csv\" in files:\n",
    "        market_price_df = pd.read_csv(os.path.join(root, \"Price_Agriculture_commodities_Week.csv\"))\n",
    "        break\n",
    "market_price_df['Arrival_Date'] = pd.to_datetime(market_price_df['Arrival_Date'], errors='coerce', dayfirst=True)\n",
    "market_price_df['year'] = market_price_df['Arrival_Date'].dt.year\n",
    "market_price_df['month'] = market_price_df['Arrival_Date'].dt.month\n",
    "market_price_df['day'] = market_price_df['Arrival_Date'].dt.day\n",
    "for price_col in ['Min Price', 'Max Price', 'Modal Price']:\n",
    "    market_price_df[price_col] = pd.to_numeric(market_price_df[price_col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T11:07:09.557295Z",
     "iopub.status.busy": "2025-04-22T11:07:09.556836Z",
     "iopub.status.idle": "2025-04-22T11:07:09.88865Z",
     "shell.execute_reply": "2025-04-22T11:07:09.888053Z",
     "shell.execute_reply.started": "2025-04-22T11:07:09.557263Z"
    },
    "id": "cxKnI5SPUY4W"
   },
   "outputs": [],
   "source": [
    "# Load crop production data\n",
    "crop_production_csv_path = os.path.join(kaustubhgupta_crop_production_in_india_path, \"crop_yield.csv\")\n",
    "\n",
    "if os.path.exists(crop_production_csv_path):\n",
    "    crop_production_df = pd.read_csv(crop_production_csv_path)\n",
    "    print(f\"Successfully loaded: {crop_production_csv_path}\")\n",
    "    print(f\"Available columns: {crop_production_df.columns.tolist()}\")\n",
    "else:\n",
    "    print(f\"Warning: File not found at {crop_production_csv_path}\")\n",
    "    crop_production_df = None\n",
    "\n",
    "# Only create visualization if data was loaded successfully\n",
    "if crop_production_df is not None and 'Crop' in crop_production_df.columns and 'Production' in crop_production_df.columns:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    crop_production = crop_production_df.groupby('Crop')['Production'].sum().sort_values(ascending=False).head(10)\n",
    "    sns.barplot(x=crop_production.index, y=crop_production.values)\n",
    "    plt.title('Top 10 Crops by Production in India')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Total Production')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping visualization due to missing data or incorrect column names\")\n",
    "    if crop_production_df is not None:\n",
    "        print(f\"Available columns: {crop_production_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T11:15:20.955748Z",
     "iopub.status.busy": "2025-04-22T11:15:20.955454Z",
     "iopub.status.idle": "2025-04-22T11:15:21.186053Z",
     "shell.execute_reply": "2025-04-22T11:15:21.185357Z",
     "shell.execute_reply.started": "2025-04-22T11:15:20.955727Z"
    },
    "id": "1gQ1OVnmUY4X"
   },
   "outputs": [],
   "source": [
    "plant_village_root = tushar5harma_plant_village_dataset_updated_path\n",
    "version_dirs = [d for d in os.listdir(plant_village_root) if os.path.isdir(os.path.join(plant_village_root, d))]\n",
    "plant_disease_path = os.path.join(plant_village_root, sorted(version_dirs)[-1]) if version_dirs else plant_village_root\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, zoom_range=0.2, validation_split=0.2)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_dir = os.path.join(plant_disease_path, 'Train')\n",
    "val_dir = os.path.join(plant_disease_path, 'Val')\n",
    "train_gen = train_datagen.flow_from_directory(train_dir, target_size=(224, 224), batch_size=32, class_mode='categorical', subset='training', shuffle=True)\n",
    "val_gen = val_datagen.flow_from_directory(val_dir, target_size=(224, 224), batch_size=32, class_mode='categorical', subset='validation', shuffle=False)\n",
    "\n",
    "class_indices = train_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T11:35:45.793568Z",
     "iopub.status.busy": "2025-04-22T11:35:45.793292Z",
     "iopub.status.idle": "2025-04-22T11:35:45.801064Z",
     "shell.execute_reply": "2025-04-22T11:35:45.80049Z",
     "shell.execute_reply.started": "2025-04-22T11:35:45.793551Z"
    },
    "id": "sxaO6GWFUY4Y"
   },
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "disease_model = Sequential([base_model, GlobalAveragePooling2D(), Dense(128, activation='relu'), Dropout(0.3), Dense(len(class_indices), activation='softmax')])\n",
    "base_model.trainable = False\n",
    "disease_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "disease_model.fit(train_gen, epochs=5, validation_data=val_gen, callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True), ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001), ModelCheckpoint(\"models/disease_detection_model.h5\", monitor='val_accuracy', save_best_only=True, verbose=0)])\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "disease_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "disease_model.fit(train_gen, epochs=2, validation_data=val_gen, callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True), ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001), ModelCheckpoint(\"models/disease_detection_model.h5\", monitor='val_accuracy', save_best_only=True, verbose=0)])print(\"âœ“ Disease detection model will be loaded from GitHub pre-trained model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T11:40:47.905731Z",
     "iopub.status.busy": "2025-04-22T11:40:47.905029Z",
     "iopub.status.idle": "2025-04-22T11:40:57.253168Z",
     "shell.execute_reply": "2025-04-22T11:40:57.25244Z",
     "shell.execute_reply.started": "2025-04-22T11:40:47.905709Z"
    },
    "id": "JFDEbhMtUY4Y"
   },
   "outputs": [],
   "source": [
    "def generate_crop_advice_with_gemini(crop_name, soil_type, season, region, N=None, P=None, K=None, temperature=None, humidity=None, rainfall=None):\n",
    "    context = f\"Crop: {crop_name}\\nRegion: {region}, India\\nSoil Type: {soil_type}\\nSeason: {season}\"\n",
    "    if N is not None and P is not None and K is not None:\n",
    "        context += f\"\\nSoil Nutrients - Nitrogen: {N} kg/ha, Phosphorus: {P} kg/ha, Potassium: {K} kg/ha\"\n",
    "    if temperature is not None:\n",
    "        context += f\"\\nTemperature: {temperature}Â°C\"\n",
    "    if humidity is not None:\n",
    "        context += f\"\\nHumidity: {humidity}%\"\n",
    "    if rainfall is not None:\n",
    "        context += f\"\\nRainfall: {rainfall} mm\"\n",
    "    prompt = f\"\"\"{context}\n",
    "\n",
    "Provide comprehensive farming guidelines for {crop_name} cultivation in {region} during {season} season.\n",
    "Include: 1. Optimal planting techniques for {soil_type} soil, 2. Water management strategies, 3. Common pests/diseases and organic management, 4. Harvesting best practices, 5. Expected yield estimates.\n",
    "Format the response in clear sections with actionable advice suitable for Indian farmers.\"\"\"\n",
    "    response = gemini_client.models.generate_content(model=\"gemini-2.5-flash\", contents=prompt)\n",
    "    return response.text if hasattr(response, 'text') else response.candidates[0].content.parts[0].text\n",
    "\n",
    "def get_disease_treatment_with_gemini(disease_name, crop_name, image=None):\n",
    "    prompt = f\"\"\"You are a plant pathologist providing treatment advice for Indian farmers.\n",
    "\n",
    "Disease: {disease_name}\n",
    "Crop: {crop_name}\n",
    "\n",
    "Provide comprehensive treatment recommendations including: 1. Immediate actions, 2. Organic treatment options, 3. Chemical treatments (if necessary), 4. Preventive measures, 5. Recovery timeline.\n",
    "Focus on solutions available in India and suitable for small-scale farmers.\"\"\"\n",
    "    response = gemini_client.models.generate_content(model=\"gemini-2.5-flash\", contents=prompt)\n",
    "    return response.text if hasattr(response, 'text') else response.candidates[0].content.parts[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_crop_recommendation(N, P, K, temperature, humidity, ph, rainfall):\n",
    "    input_data = np.array([[N, P, K, temperature, humidity, ph, rainfall]])\n",
    "    input_scaled = scaler.transform(input_data)\n",
    "    prediction = rf_model.predict(input_scaled)\n",
    "    probabilities = rf_model.predict_proba(input_scaled)[0]\n",
    "    predicted_crop = label_encoder.inverse_transform(prediction)[0]\n",
    "    top_3_indices = np.argsort(probabilities)[-3:][::-1]\n",
    "    top_3_crops = label_encoder.inverse_transform(top_3_indices)\n",
    "    top_3_probs = probabilities[top_3_indices]\n",
    "    recommendations = \"\\n\".join([f\"{i+1}. {crop}: {prob*100:.2f}% confidence\" for i, (crop, prob) in enumerate(zip(top_3_crops, top_3_probs))])\n",
    "    import datetime\n",
    "    current_month = datetime.datetime.now().month\n",
    "    season = \"Kharif\" if current_month in [6, 7, 8, 9, 10] else \"Rabi\" if current_month in [11, 12, 1, 2] else \"Summer\"\n",
    "    advice = generate_crop_advice_with_gemini(predicted_crop, \"Based on your inputs\", season, \"Your region\", N=N, P=P, K=K, temperature=temperature, humidity=humidity, rainfall=rainfall)\n",
    "    return f\"## Recommended Crop: {predicted_crop}\\n\\n### Top 3 Recommendations:\\n{recommendations}\\n\\n### Detailed Farming Guidelines:\\n{advice}\"\n",
    "\n",
    "def download_pretrained_disease_model():\n",
    "    \"\"\"\n",
    "    Download pre-trained disease detection model from GitHub\n",
    "    Handles Keras version compatibility issues by fixing model config\n",
    "    \"\"\"\n",
    "    import h5py\n",
    "    import json\n",
    "    \n",
    "    model_url = \"https://raw.githubusercontent.com/george-bobby/crop-prediction/main/models/disease_detection_model.h5\"\n",
    "    models_dir = os.path.join(os.getcwd(), \"models\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    model_path = os.path.join(models_dir, \"disease_detection_model.h5\")\n",
    "    \n",
    "    def fix_h5_config(h5_path):\n",
    "        \"\"\"Remove quantization_config from h5 file to fix compatibility issues\"\"\"\n",
    "        try:\n",
    "            with h5py.File(h5_path, 'r+') as f:\n",
    "                if 'model_config' in f.attrs:\n",
    "                    config_str = f.attrs['model_config']\n",
    "                    if isinstance(config_str, bytes):\n",
    "                        config_str = config_str.decode('utf-8')\n",
    "                    \n",
    "                    config = json.loads(config_str)\n",
    "                    \n",
    "                    # Remove quantization_config from all layers recursively\n",
    "                    def clean_config(obj):\n",
    "                        if isinstance(obj, dict):\n",
    "                            obj.pop('quantization_config', None)\n",
    "                            for key, val in obj.items():\n",
    "                                clean_config(val)\n",
    "                        elif isinstance(obj, list):\n",
    "                            for item in obj:\n",
    "                                clean_config(item)\n",
    "                    \n",
    "                    clean_config(config)\n",
    "                    f.attrs['model_config'] = json.dumps(config)\n",
    "                    print(f\"  âœ“ Fixed model config (removed quantization_config)\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âš  Could not auto-fix config: {str(e)[:50]}\")\n",
    "    \n",
    "    # Check if model already exists\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"âœ“ Using cached pre-trained model: {model_path}\")\n",
    "        try:\n",
    "            fix_h5_config(model_path)\n",
    "            return tf.keras.models.load_model(model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"âš  Failed to load cached model: {str(e)[:80]}\")\n",
    "            os.remove(model_path)\n",
    "    \n",
    "    # Download model from GitHub\n",
    "    print(f\"Downloading pre-trained disease detection model from GitHub...\")\n",
    "    try:\n",
    "        urllib.request.urlretrieve(model_url, model_path)\n",
    "        print(f\"âœ“ Model downloaded successfully\")\n",
    "        \n",
    "        # Fix the config before loading\n",
    "        fix_h5_config(model_path)\n",
    "        \n",
    "        # Try to load\n",
    "        try:\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "            print(f\"âœ“ Model loaded successfully\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— Load error: {str(e)[:80]}\")\n",
    "            raise\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Failed to download/process model: {str(e)[:100]}\")\n",
    "        raise\n",
    "\n",
    "# Load the pre-trained model\n",
    "disease_model = download_pretrained_disease_model()\n",
    "\n",
    "def detect_plant_disease(image, crop_type=\"Tomato\"):\n",
    "    if image is None:\n",
    "        return \"Please upload an image\"\n",
    "    img_array = np.array(image.resize((224, 224)))\n",
    "    if len(img_array.shape) == 2:\n",
    "        img_array = np.stack([img_array] * 3, axis=-1)\n",
    "    img_array = img_array / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    predictions = disease_model.predict(img_array, verbose=0)\n",
    "    predicted_idx = np.argmax(predictions[0])\n",
    "    confidence = predictions[0][predicted_idx]\n",
    "    \n",
    "    # Class mapping for common plant diseases\n",
    "    class_mapping = {\n",
    "        0: \"Early Blight\", 1: \"Late Blight\", 2: \"Healthy\", 3: \"Septoria Leaf Spot\",\n",
    "        4: \"Spider Mites\", 5: \"Target Spot\", 6: \"Yellow Leaf Curl Virus\"\n",
    "    }\n",
    "    detected_disease = class_mapping.get(predicted_idx, f\"Disease_{predicted_idx}\")\n",
    "    \n",
    "    treatment = get_disease_treatment_with_gemini(detected_disease, crop_type, image=image)\n",
    "    return f\"## Analysis Complete!\\n\\n**Crop Type:** {crop_type}\\n**Detected Issue:** {detected_disease} (Confidence: {confidence*100:.2f}%)\\n\\n### Treatment Recommendations:\\n{treatment}\"\n",
    "\n",
    "def analyze_market_prices(commodity, state, date_range=30):\n",
    "    filtered_df = market_price_df[(market_price_df['Commodity'].str.contains(commodity, case=False, na=False)) & (market_price_df['State'].str.contains(state, case=False, na=False))]\n",
    "    if filtered_df.empty:\n",
    "        return f\"No data found for {commodity} in {state}\", None\n",
    "    if 'Arrival_Date' in filtered_df.columns and not filtered_df['Arrival_Date'].isna().all():\n",
    "        max_date = filtered_df['Arrival_Date'].max()\n",
    "        cutoff_date = max_date - timedelta(days=date_range)\n",
    "        filtered_df = filtered_df[filtered_df['Arrival_Date'] >= cutoff_date]\n",
    "    if filtered_df.empty:\n",
    "        return f\"No data found for {commodity} in {state} within the last {date_range} days\", None\n",
    "    \n",
    "    avg_modal_price = filtered_df['Modal Price'].mean()\n",
    "    min_price = filtered_df['Min Price'].min()\n",
    "    max_price = filtered_df['Max Price'].max()\n",
    "    recent_modal = filtered_df.nlargest(5, 'Arrival_Date')['Modal Price'].mean()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    daily_avg = filtered_df.groupby('Arrival_Date')['Modal Price'].mean().sort_index()\n",
    "    plt.plot(daily_avg.index, daily_avg.values, marker='o', linestyle='-', linewidth=2)\n",
    "    plt.title(f'{commodity} Price Trend in {state}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Modal Price (â‚¹/Quintal)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    market_avg = filtered_df.groupby('Market')['Modal Price'].mean().sort_values(ascending=False).head(10)\n",
    "    plt.barh(range(len(market_avg)), market_avg.values)\n",
    "    plt.yticks(range(len(market_avg)), market_avg.index)\n",
    "    plt.xlabel('Average Modal Price (â‚¹/Quintal)')\n",
    "    plt.title(f'Top 10 Markets by Price')\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')\n",
    "    buf.seek(0)\n",
    "    plt.close()\n",
    "    price_plot = Image.open(buf)\n",
    "    \n",
    "    recent_trend = daily_avg.iloc[-5:].mean() - daily_avg.iloc[-10:-5].mean() if len(daily_avg) > 1 else 0\n",
    "    trend_direction = \"Upward\" if recent_trend > 0 else \"Downward\"\n",
    "    trend_percentage = (recent_trend / daily_avg.iloc[-10:-5].mean()) * 100 if len(daily_avg) > 1 else 0\n",
    "    \n",
    "    result = f\"## Market Price Analysis: {commodity} in {state}\\n\\n### Current Market Statistics:\\n- **Average Modal Price:** â‚¹{avg_modal_price:.2f} per quintal\\n- **Recent Average:** â‚¹{recent_modal:.2f} per quintal\\n- **Price Range:** â‚¹{min_price:.2f} - â‚¹{max_price:.2f}\\n- **Price Trend:** {trend_direction} ({trend_percentage:.2f}%)\\n\\n### Market Insights:\\n- Total Markets: {filtered_df['Market'].nunique()}\\n- Total Entries: {len(filtered_df)}\\n- Date Range: {filtered_df['Arrival_Date'].min().strftime('%d-%m-%Y')} to {filtered_df['Arrival_Date'].max().strftime('%d-%m-%Y')}\\n\\n### Recommendation:\\n{'Consider selling soon as prices are declining.' if trend_direction == 'Downward' else 'Prices are rising - you may wait for better rates if storage is available.'}\"\n",
    "    return result, price_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load enriched crop yield dataset from asishpandey dataset\n",
    "# We'll merge Final_Dataset_after_temperature.csv with Fertilizer.csv to get all required columns\n",
    "\n",
    "# Load the temperature/rainfall enriched dataset\n",
    "temp_dataset_path = os.path.join(asishpandey_crop_production_in_india, \"Final_Dataset_after_temperature.csv\")\n",
    "fertilizer_path = os.path.join(asishpandey_crop_production_in_india, \"Fertilizer.csv\")\n",
    "\n",
    "if os.path.exists(temp_dataset_path) and os.path.exists(fertilizer_path):\n",
    "    # Load both datasets\n",
    "    crop_yield_base = pd.read_csv(temp_dataset_path)\n",
    "    fertilizer_df = pd.read_csv(fertilizer_path)\n",
    "    \n",
    "    print(f\"âœ“ Loaded temperature/rainfall dataset: {crop_yield_base.shape}\")\n",
    "    print(f\"âœ“ Loaded fertilizer dataset: {fertilizer_df.shape}\")\n",
    "    \n",
    "    # Normalize crop names for merging (lowercase)\n",
    "    crop_yield_base['Crop'] = crop_yield_base['Crop'].str.lower().str.strip()\n",
    "    fertilizer_df['Crop'] = fertilizer_df['Crop'].str.lower().str.strip()\n",
    "    \n",
    "    # Merge datasets on Crop name to add N, P, K, pH columns\n",
    "    crop_yield_df = crop_yield_base.merge(\n",
    "        fertilizer_df[['Crop', 'N', 'P', 'K', 'pH']], \n",
    "        on='Crop', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Fill missing N, P, K, pH values with median values\n",
    "    for col in ['N', 'P', 'K', 'pH']:\n",
    "        if col in crop_yield_df.columns:\n",
    "            median_val = crop_yield_df[col].median()\n",
    "            crop_yield_df[col] = crop_yield_df[col].fillna(median_val)\n",
    "    \n",
    "    print(f\"\\nâœ“ Successfully merged datasets!\")\n",
    "    print(f\"Final dataset shape: {crop_yield_df.shape}\")\n",
    "    print(f\"Columns: {crop_yield_df.columns.tolist()}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(crop_yield_df.head())\n",
    "    print(f\"\\nMissing values per column:\")\n",
    "    print(crop_yield_df.isnull().sum())\n",
    "    \n",
    "else:\n",
    "    print(f\"âš  Error: Required dataset files not found\")\n",
    "    print(f\"Looking for:\")\n",
    "    print(f\"  - {temp_dataset_path}\")\n",
    "    print(f\"  - {fertilizer_path}\")\n",
    "    raise FileNotFoundError(\"Cannot find required dataset files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_yield_features(df):\n",
    "    \"\"\"\n",
    "    Create 80+ advanced engineered features for crop yield prediction\n",
    "    Includes NPK ratios, climate stress, interactions, polynomials, and binned features\n",
    "    \"\"\"\n",
    "    d = df.copy()\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # 1. NUTRIENT ENGINEERING (NPK ratios & interactions)\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    d['NPK_sum'] = d['N'] + d['P'] + d['K']\n",
    "    d['NPK_product'] = np.log1p(d['N'] * d['P'] * d['K'])\n",
    "    d['NP_ratio'] = d['N'] / (d['P'] + 1)\n",
    "    d['NK_ratio'] = d['N'] / (d['K'] + 1)\n",
    "    d['PK_ratio'] = d['P'] / (d['K'] + 1)\n",
    "    d['N_dominance'] = d['N'] / (d['NPK_sum'] + 1)\n",
    "    d['P_dominance'] = d['P'] / (d['NPK_sum'] + 1)\n",
    "    d['K_dominance'] = d['K'] / (d['NPK_sum'] + 1)\n",
    "    d['nutrient_balance'] = 1 - (np.abs(d['N_dominance'] - 0.33) + np.abs(d['P_dominance'] - 0.33))\n",
    "    d['NPK_harmonic'] = 3 / ((1/(d['N']+1)) + (1/(d['P']+1)) + (1/(d['K']+1)))\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # 2. CLIMATE & ENVIRONMENTAL INTERACTIONS\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    d['temp_rain'] = d['temperature'] * d['rainfall']\n",
    "    d['temp_pH'] = d['temperature'] * d['pH']\n",
    "    d['rain_pH'] = d['rainfall'] * d['pH']\n",
    "    d['moisture_index'] = d['rainfall'] / (d['temperature'] + 1)\n",
    "    d['heat_stress'] = np.where(d['temperature'] > 30, (d['temperature'] - 30) ** 2, 0)\n",
    "    d['drought_stress'] = np.where(d['rainfall'] < 500, (500 - d['rainfall']) ** 1.5, 0)\n",
    "    d['optimal_temp'] = np.exp(-((d['temperature'] - 25) ** 2) / 100)\n",
    "    d['optimal_rain'] = np.exp(-((d['rainfall'] - 800) ** 2) / 100000)\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # 3. SOIL QUALITY FEATURES\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    d['pH_dist'] = np.abs(d['pH'] - 6.5)\n",
    "    d['soil_fert'] = d['NPK_sum'] * (1 - d['pH_dist'] / 7)\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # 4. CROP-LEVEL STATISTICS (safe - no target leakage for tree models)\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    for col in ['N', 'P', 'K', 'temperature', 'rainfall', 'pH']:\n",
    "        d[f'{col}_crop_mean'] = d.groupby('Crop')[col].transform('mean')\n",
    "        d[f'{col}_deviation'] = d[col] - d[f'{col}_crop_mean']\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # 5. NPK & CLIMATE INTERACTIONS\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    d['NPK_temp'] = d['NPK_sum'] * d['temperature']\n",
    "    d['NPK_rain'] = d['NPK_sum'] * d['rainfall']\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # 6. POLYNOMIAL FEATURES (for key nutrients & climate)\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    for col in ['N', 'P', 'K', 'temperature', 'rainfall']:\n",
    "        d[f'{col}_sq'] = d[col] ** 2\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # 7. LOG-TRANSFORMED FEATURES (for right-skewed distributions)\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    for col in ['N', 'P', 'K', 'rainfall']:\n",
    "        d[f'{col}_log'] = np.log1p(d[col])\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # 8. BINNED/CATEGORICAL FEATURES (discretization for nonlinear patterns)\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    for col, bins in [('N', 10), ('P', 10), ('K', 10), ('temperature', 10), ('rainfall', 10)]:\n",
    "        d[f'{col}_bin'] = pd.cut(d[col], bins=bins, labels=False)\n",
    "    \n",
    "    return d\n",
    "\n",
    "print(\"âœ“ Feature engineering function created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_yield_data(df):\n",
    "    \"\"\"\n",
    "    Data cleaning pipeline for crop yield prediction\n",
    "    - Removes duplicates\n",
    "    - Filters outliers using per-crop IQR method\n",
    "    - Removes rare crops (< 5 samples)\n",
    "    - Handles missing values\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ§¹ DATA CLEANING PIPELINE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    initial_shape = df.shape\n",
    "    d = df.copy()\n",
    "    \n",
    "    # Remove duplicates\n",
    "    d = d.drop_duplicates()\n",
    "    print(f\"\\n  After removing duplicates: {d.shape[0]:,} samples (removed {initial_shape[0] - d.shape[0]})\")\n",
    "    \n",
    "    # Target column detection\n",
    "    target_col = None\n",
    "    if 'Production_in_tons' in d.columns:\n",
    "        target_col = 'Production_in_tons'\n",
    "    elif 'Production' in d.columns:\n",
    "        target_col = 'Production'\n",
    "    else:\n",
    "        prod_cols = [col for col in d.columns if 'production' in col.lower()]\n",
    "        if prod_cols:\n",
    "            target_col = prod_cols[0]\n",
    "    \n",
    "    if target_col is None:\n",
    "        raise ValueError(\"No production column found\")\n",
    "    \n",
    "    # Remove missing and invalid target values\n",
    "    d = d.dropna(subset=[target_col])\n",
    "    d = d[d[target_col] > 0]\n",
    "    d = d[d[target_col] < 200]\n",
    "    print(f\"  After removing invalid targets: {d.shape[0]:,} samples\")\n",
    "    \n",
    "    # Clean numeric columns\n",
    "    numeric_cols = ['N', 'P', 'K', 'temperature', 'rainfall', 'pH']\n",
    "    for col in numeric_cols:\n",
    "        if col in d.columns:\n",
    "            d = d[d[col].notna()]\n",
    "            d = d[(d[col] >= 0) & (d[col] < 1000)]\n",
    "    \n",
    "    # Per-crop IQR outlier removal (3rd-97th percentile)\n",
    "    print(\"\\n  ğŸ” Per-crop IQR outlier removal...\")\n",
    "    df_clean = d.copy()\n",
    "    outlier_count = 0\n",
    "    \n",
    "    for crop in df_clean['Crop'].unique():\n",
    "        crop_mask = df_clean['Crop'] == crop\n",
    "        crop_data = df_clean[crop_mask]\n",
    "        \n",
    "        if len(crop_data) < 30:\n",
    "            continue\n",
    "        \n",
    "        Q1 = crop_data[target_col].quantile(0.03)\n",
    "        Q3 = crop_data[target_col].quantile(0.97)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 2.5 * IQR\n",
    "        upper = Q3 + 2.5 * IQR\n",
    "        \n",
    "        valid_mask = crop_mask & (df_clean[target_col] >= lower) & (df_clean[target_col] <= upper)\n",
    "        removed = crop_mask & ~valid_mask\n",
    "        outlier_count += removed.sum()\n",
    "        df_clean = df_clean[~removed]\n",
    "    \n",
    "    print(f\"    Removed {outlier_count} outliers\")\n",
    "    print(f\"    Final shape: {df_clean.shape[0]:,} samples\")\n",
    "    \n",
    "    # Filter rare crops (need >= 5 samples for stratified split)\n",
    "    print(\"\\n  ğŸ“Š Filtering rare crops (< 5 samples)...\")\n",
    "    crop_counts = df_clean['Crop'].value_counts()\n",
    "    valid_crops = crop_counts[crop_counts >= 5].index\n",
    "    df_clean = df_clean[df_clean['Crop'].isin(valid_crops)].copy().reset_index(drop=True)\n",
    "    print(f\"    Kept {len(valid_crops)} crops, removed {len(crop_counts) - len(valid_crops)} rare crops\")\n",
    "    print(f\"    Final shape: {df_clean.shape[0]:,} samples\")\n",
    "    \n",
    "    print(\"\\nâœ… Data cleaning complete!\")\n",
    "    return df_clean.reset_index(drop=True)\n",
    "\n",
    "print(\"âœ“ Data cleaning function created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yield_preprocessor(df=None):\n",
    "    \"\"\"\n",
    "    Create preprocessor for crop yield prediction\n",
    "    If df is provided, extract actual categories from the data\n",
    "    \"\"\"\n",
    "    categorical_cols = ['State_Name', 'Crop_Type', 'Crop']\n",
    "    numerical_cols = ['N', 'P', 'K', 'pH', 'rainfall', 'temperature', 'Area_in_hectares']\n",
    "    \n",
    "    # If dataframe is provided, get actual categories from data\n",
    "    if df is not None:\n",
    "        state_name_list = sorted(df['State_Name'].str.lower().unique().tolist())\n",
    "        crop_type_list = sorted(df['Crop_Type'].str.lower().unique().tolist())\n",
    "        crop_list = sorted(df['Crop'].str.lower().unique().tolist())\n",
    "        print(f\"Extracted {len(state_name_list)} states, {len(crop_type_list)} crop types, {len(crop_list)} crops from data\")\n",
    "    else:\n",
    "        # Fallback to default lists (not recommended - may cause errors)\n",
    "        state_name_list = ['andaman and nicobar islands', 'andhra pradesh', 'arunachal pradesh', \n",
    "                          'assam', 'bihar', 'chandigarh', 'chhattisgarh', 'dadra and nagar haveli', \n",
    "                          'goa', 'gujarat', 'haryana', 'himachal pradesh', 'jammu and kashmir', \n",
    "                          'jharkhand', 'karnataka', 'kerala', 'madhya pradesh', 'maharashtra', \n",
    "                          'manipur', 'meghalaya', 'mizoram', 'nagaland', 'odisha', 'puducherry', \n",
    "                          'punjab', 'rajasthan', 'sikkim', 'tamil nadu', 'telangana', 'tripura', \n",
    "                          'uttar pradesh', 'uttarakhand', 'west bengal']\n",
    "        \n",
    "        crop_type_list = ['kharif', 'rabi', 'whole year', 'summer']\n",
    "        crop_list = ['rice', 'turmeric', 'sweetpotato', 'moong', 'maize', 'cashewnuts', \n",
    "                    'blackpepper', 'arecanut', 'pumpkin', 'cardamom', 'soyabean', 'banana', \n",
    "                    'brinjal', 'grapes', 'orange', 'tapioca', 'ladyfinger', 'barley', 'drumstick', \n",
    "                    'jute', 'sunflower', 'apple', 'jackfruit', 'bottlegourd', 'cotton', 'coffee', \n",
    "                    'sesamum', 'garlic', 'potato', 'beetroot', 'onion', 'rapeseed', 'horsegram', \n",
    "                    'ragi', 'jowar', 'wheat', 'coriander', 'ginger', 'cabbage', 'mango', 'tomato', \n",
    "                    'cucumber', 'papaya', 'ridgegourd', 'bittergourd', 'cauliflower', 'ashgourd', \n",
    "                    'pomegranate', 'watermelon', 'carrot', 'blackgram', 'radish', 'pineapple']\n",
    "    \n",
    "    num_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    cat_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ordinalencoder', OrdinalEncoder(\n",
    "            categories=[state_name_list, crop_type_list, crop_list],\n",
    "            handle_unknown='use_encoded_value',\n",
    "            unknown_value=-1\n",
    "        )),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num_pipeline', num_pipeline, numerical_cols),\n",
    "        ('cat_pipeline', cat_pipeline, categorical_cols)\n",
    "    ])\n",
    "    \n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_soil_health(Clay, OM, CEC, pH, V, exP, exK, exCa, exMg):\n",
    "    \"\"\"\n",
    "    Comprehensive soil health analysis with 9-parameter scoring system\n",
    "    Returns detailed HTML report with ratings and recommendations\n",
    "    \"\"\"\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # Parameter ratings (Excellent/Good/Fair/Marginal)\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    def rate_parameter(value, param_name):\n",
    "        \"\"\"Rate individual soil parameters\"\"\"\n",
    "        ratings = {\n",
    "            'Clay': [(300, 'Excellent', '#27ae60'), (400, 'Good', '#3498db'), (500, 'Fair', '#f39c12'), (float('inf'), 'Marginal', '#e74c3c')],\n",
    "            'OM': [(40, 'Excellent', '#27ae60'), (30, 'Good', '#3498db'), (20, 'Fair', '#f39c12'), (float('inf'), 'Marginal', '#e74c3c')],\n",
    "            'CEC': [(100, 'Excellent', '#27ae60'), (80, 'Good', '#3498db'), (50, 'Fair', '#f39c12'), (float('inf'), 'Marginal', '#e74c3c')],\n",
    "            'pH': [(7, 'Excellent', '#27ae60'), (6.5, 'Good', '#3498db'), (5.5, 'Fair', '#f39c12'), (float('inf'), 'Marginal', '#e74c3c')],\n",
    "            'V': [(80, 'Excellent', '#27ae60'), (60, 'Good', '#3498db'), (40, 'Fair', '#f39c12'), (float('inf'), 'Marginal', '#e74c3c')],\n",
    "            'exP': [(40, 'Excellent', '#27ae60'), (25, 'Good', '#3498db'), (15, 'Fair', '#f39c12'), (float('inf'), 'Marginal', '#e74c3c')],\n",
    "            'exK': [(10, 'Excellent', '#27ae60'), (5, 'Good', '#3498db'), (2, 'Fair', '#f39c12'), (float('inf'), 'Marginal', '#e74c3c')],\n",
    "            'exCa': [(80, 'Excellent', '#27ae60'), (50, 'Good', '#3498db'), (30, 'Fair', '#f39c12'), (float('inf'), 'Marginal', '#e74c3c')],\n",
    "            'exMg': [(50, 'Excellent', '#27ae60'), (30, 'Good', '#3498db'), (15, 'Fair', '#f39c12'), (float('inf'), 'Marginal', '#e74c3c')],\n",
    "        }\n",
    "        \n",
    "        for threshold, rating, color in ratings.get(param_name, []):\n",
    "            if value <= threshold:\n",
    "                return rating, color, threshold\n",
    "        return 'Unknown', '#95a5a6', 0\n",
    "    \n",
    "    # Rate all parameters\n",
    "    params = {\n",
    "        'Clay': Clay,\n",
    "        'OM': OM,\n",
    "        'CEC': CEC,\n",
    "        'pH': pH,\n",
    "        'V': V,\n",
    "        'exP': exP,\n",
    "        'exK': exK,\n",
    "        'exCa': exCa,\n",
    "        'exMg': exMg\n",
    "    }\n",
    "    \n",
    "    ratings = {}\n",
    "    colors = {}\n",
    "    for param, value in params.items():\n",
    "        rating, color, _ = rate_parameter(value, param)\n",
    "        ratings[param] = rating\n",
    "        colors[param] = color\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # Calculate composite fertility score (0-100)\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    scaler_minmax = MinMaxScaler(feature_range=(0, 100))\n",
    "    \n",
    "    # Normalize parameters to 0-100 scale\n",
    "    param_values = np.array([[Clay, OM, CEC, pH, V, exP, exK, exCa, exMg]])\n",
    "    param_max = np.array([[500, 50, 150, 8, 100, 100, 15, 100, 60]])\n",
    "    \n",
    "    normalized = (param_values / param_max) * 100\n",
    "    \n",
    "    # Weighted fertility score\n",
    "    weights = {\n",
    "        'OM': 0.15,      # Organic matter\n",
    "        'pH': 0.15,      # pH\n",
    "        'exP': 0.13,     # Phosphorus\n",
    "        'exK': 0.13,     # Potassium\n",
    "        'CEC': 0.12,     # Cation exchange capacity\n",
    "        'exCa': 0.10,    # Calcium\n",
    "        'exMg': 0.10,    # Magnesium\n",
    "        'V': 0.07,       # Base saturation\n",
    "        'Clay': 0.05     # Clay content\n",
    "    }\n",
    "    \n",
    "    fertility_score = sum([\n",
    "        (OM / 50) * 100 * weights['OM'],\n",
    "        (pH / 8) * 100 * weights['pH'],\n",
    "        (exP / 100) * 100 * weights['exP'],\n",
    "        (exK / 15) * 100 * weights['exK'],\n",
    "        (CEC / 150) * 100 * weights['CEC'],\n",
    "        (exCa / 100) * 100 * weights['exCa'],\n",
    "        (exMg / 60) * 100 * weights['exMg'],\n",
    "        (V / 100) * 100 * weights['V'],\n",
    "        (Clay / 500) * 100 * weights['Clay']\n",
    "    ]) / sum(weights.values())\n",
    "    \n",
    "    fertility_score = max(0, min(100, fertility_score))\n",
    "    \n",
    "    # Overall health color\n",
    "    if fertility_score >= 80:\n",
    "        health_color = '#27ae60'\n",
    "        health_status = 'Excellent'\n",
    "    elif fertility_score >= 60:\n",
    "        health_color = '#3498db'\n",
    "        health_status = 'Good'\n",
    "    elif fertility_score >= 40:\n",
    "        health_color = '#f39c12'\n",
    "        health_status = 'Fair'\n",
    "    else:\n",
    "        health_color = '#e74c3c'\n",
    "        health_status = 'Marginal'\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # Generate HTML report\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    html_report = f\"\"\"\n",
    "    <div style=\"font-family: Arial, sans-serif; line-height: 1.6; color: #333;\">\n",
    "        \n",
    "        <!-- Overall Health Score -->\n",
    "        <div style=\"background: {health_color}; color: white; padding: 20px; border-radius: 8px; margin-bottom: 20px;\">\n",
    "            <h2 style=\"margin: 0 0 10px 0;\">ğŸŒ± Soil Health Score: {fertility_score:.1f}/100</h2>\n",
    "            <p style=\"margin: 0; font-size: 18px;\">Status: <strong>{health_status}</strong></p>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Parameter Ratings -->\n",
    "        <div style=\"margin-bottom: 20px;\">\n",
    "            <h3>ğŸ“Š Parameter Ratings</h3>\n",
    "            <table style=\"width: 100%; border-collapse: collapse;\">\n",
    "                <tr style=\"background: #f5f5f5;\">\n",
    "                    <th style=\"border: 1px solid #ddd; padding: 10px; text-align: left;\">Parameter</th>\n",
    "                    <th style=\"border: 1px solid #ddd; padding: 10px; text-align: center;\">Value</th>\n",
    "                    <th style=\"border: 1px solid #ddd; padding: 10px; text-align: center;\">Rating</th>\n",
    "                </tr>\n",
    "    \"\"\"\n",
    "    \n",
    "    param_labels = {\n",
    "        'Clay': 'Clay Content (g/kg)',\n",
    "        'OM': 'Organic Matter (g/kg)',\n",
    "        'CEC': 'CEC (cmolâ‚Š/kg)',\n",
    "        'pH': 'pH Value',\n",
    "        'V': 'Base Saturation (%)',\n",
    "        'exP': 'Available P (mg/kg)',\n",
    "        'exK': 'Available K (mg/kg)',\n",
    "        'exCa': 'Available Ca (mg/kg)',\n",
    "        'exMg': 'Available Mg (mg/kg)'\n",
    "    }\n",
    "    \n",
    "    for param in ['Clay', 'OM', 'CEC', 'pH', 'V', 'exP', 'exK', 'exCa', 'exMg']:\n",
    "        rating = ratings[param]\n",
    "        color = colors[param]\n",
    "        value = params[param]\n",
    "        html_report += f\"\"\"\n",
    "                <tr>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 10px;\">{param_labels[param]}</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 10px; text-align: center;\">{value:.1f}</td>\n",
    "                    <td style=\"border: 1px solid #ddd; padding: 10px; text-align: center; background: {color}; color: white; font-weight: bold;\">{rating}</td>\n",
    "                </tr>\n",
    "        \"\"\"\n",
    "    \n",
    "    html_report += \"\"\"\n",
    "            </table>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Key Observations & Recommendations -->\n",
    "        <div style=\"margin-bottom: 20px;\">\n",
    "            <h3>ğŸ’¡ Key Observations & Recommendations</h3>\n",
    "            <ul>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate recommendations based on parameters\n",
    "    recommendations = []\n",
    "    \n",
    "    if OM < 20:\n",
    "        recommendations.append(f\"<li><strong>Organic Matter Low ({OM:.1f} g/kg):</strong> Add compost, farm yard manure (FYM), or green manure. Target: 30+ g/kg</li>\")\n",
    "    elif OM >= 30:\n",
    "        recommendations.append(f\"<li><strong>Organic Matter Excellent ({OM:.1f} g/kg):</strong> Maintain by regular addition of organic amendments</li>\")\n",
    "    \n",
    "    if pH < 5.5:\n",
    "        recommendations.append(f\"<li><strong>pH Very Acidic ({pH:.1f}):</strong> Apply lime (CaCOâ‚ƒ) @ 2-5 t/ha; target pH 6.0-6.5</li>\")\n",
    "    elif pH > 7.5:\n",
    "        recommendations.append(f\"<li><strong>pH Alkaline ({pH:.1f}):</strong> Apply sulfur or acidifying agents; difficult to correct - focus on crop selection</li>\")\n",
    "    \n",
    "    if exP < 15:\n",
    "        recommendations.append(f\"<li><strong>Phosphorus Deficient ({exP:.1f} mg/kg):</strong> Apply P fertilizer (20-30 kg Pâ‚‚Oâ‚…/ha) or DAP/SSP</li>\")\n",
    "    \n",
    "    if exK < 2:\n",
    "        recommendations.append(f\"<li><strong>Potassium Deficient ({exK:.1f} mg/kg):</strong> Apply K fertilizer (40-60 kg Kâ‚‚O/ha) or Muriate of Potash</li>\")\n",
    "    \n",
    "    if exCa < 30:\n",
    "        recommendations.append(f\"<li><strong>Calcium Deficient ({exCa:.1f} mg/kg):</strong> Apply lime or gypsum @ 1-2 t/ha</li>\")\n",
    "    \n",
    "    if exMg < 15:\n",
    "        recommendations.append(f\"<li><strong>Magnesium Deficient ({exMg:.1f} mg/kg):</strong> Apply MgSOâ‚„ (Epsom salt) @ 500 kg/ha</li>\")\n",
    "    \n",
    "    if CEC < 50:\n",
    "        recommendations.append(f\"<li><strong>Low CEC ({CEC:.1f} cmolâ‚Š/kg):</strong> Increase organic matter; improve soil structure with continuous manuring</li>\")\n",
    "    \n",
    "    if V < 40:\n",
    "        recommendations.append(f\"<li><strong>Low Base Saturation ({V:.1f}%):</strong> High acidity; apply lime to increase saturation to 60%+</li>\")\n",
    "    \n",
    "    if Clay < 200:\n",
    "        recommendations.append(f\"<li><strong>Low Clay Content ({Clay:.1f} g/kg):</strong> Likely sandy soil; add clay/silt through amendments or mulching</li>\")\n",
    "    elif Clay > 400:\n",
    "        recommendations.append(f\"<li><strong>High Clay Content ({Clay:.1f} g/kg):</strong> Risk of waterlogging; ensure good drainage; add organic matter for structure</li>\")\n",
    "    \n",
    "    if not recommendations:\n",
    "        html_report += \"<li><strong>âœ“ Soil Parameters Look Healthy:</strong> Continue with regular soil testing (every 2-3 years)</li>\"\n",
    "    else:\n",
    "        html_report += \"\".join(recommendations)\n",
    "    \n",
    "    html_report += \"\"\"\n",
    "            </ul>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Additional Guidance -->\n",
    "        <div style=\"background: #ecf0f1; padding: 15px; border-left: 4px solid #3498db; border-radius: 4px;\">\n",
    "            <h4 style=\"margin-top: 0;\">ğŸ“‹ Soil Testing Recommendations</h4>\n",
    "            <p><strong>Test Frequency:</strong> Every 2-3 years for major nutrients; annually for intensive cropping</p>\n",
    "            <p><strong>Best Time to Test:</strong> 1-2 months before sowing season</p>\n",
    "            <p><strong>Sampling Depth:</strong> 0-15 cm for normal crops; 0-30 cm for perennials</p>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    return html_report, fertility_score, health_status, health_color\n",
    "\n",
    "\n",
    "def get_crop_recommendations_for_soil(Clay, OM, CEC, pH, V, exP, exK, exCa, exMg):\n",
    "    \"\"\"\n",
    "    Get suitable crop recommendations based on soil parameters\n",
    "    Database of 92 crops with their requirements\n",
    "    \"\"\"\n",
    "    \n",
    "    # Comprehensive 92-crop database with pH and major nutrient requirements\n",
    "    crop_db = {\n",
    "        # Cereals\n",
    "        'Rice': {'pH': (5.0, 6.5), 'P': 20, 'K': 2.0, 'category': 'Cereal, Flood Tolerant'},\n",
    "        'Wheat': {'pH': (6.0, 7.5), 'P': 25, 'K': 2.5, 'category': 'Cereal, Cold Season'},\n",
    "        'Maize': {'pH': (5.8, 7.0), 'P': 20, 'K': 2.5, 'category': 'Cereal, High Yield'},\n",
    "        'Barley': {'pH': (6.0, 7.5), 'P': 20, 'K': 2.0, 'category': 'Cereal'},\n",
    "        'Jowar': {'pH': (6.5, 8.0), 'P': 15, 'K': 1.5, 'category': 'Millet, Drought Tolerant'},\n",
    "        'Bajra': {'pH': (6.0, 7.5), 'P': 12, 'K': 1.5, 'category': 'Millet, Drought Tolerant'},\n",
    "        'Ragi': {'pH': (5.5, 7.0), 'P': 15, 'K': 2.0, 'category': 'Millet'},\n",
    "        \n",
    "        # Pulses\n",
    "        'Gram': {'pH': (6.0, 7.5), 'P': 20, 'K': 2.0, 'category': 'Pulse, Cool Season'},\n",
    "        'Arhar': {'pH': (6.0, 7.5), 'P': 20, 'K': 2.0, 'category': 'Pulse'},\n",
    "        'Moong': {'pH': (6.0, 7.5), 'P': 15, 'K': 1.5, 'category': 'Pulse, Summer'},\n",
    "        'Urad': {'pH': (6.0, 7.5), 'P': 15, 'K': 1.5, 'category': 'Pulse'},\n",
    "        'Masoor': {'pH': (6.0, 7.5), 'P': 20, 'K': 2.0, 'category': 'Pulse, Winter'},\n",
    "        'Groundnut': {'pH': (5.5, 6.5), 'P': 20, 'K': 2.5, 'category': 'Legume, Oil Crop'},\n",
    "        'Soyabean': {'pH': (6.0, 7.0), 'P': 20, 'K': 2.0, 'category': 'Legume, High Protein'},\n",
    "        \n",
    "        # Oilseeds\n",
    "        'Mustard': {'pH': (6.0, 7.5), 'P': 20, 'K': 2.0, 'category': 'Oilseed, Winter'},\n",
    "        'Sunflower': {'pH': (6.5, 7.5), 'P': 20, 'K': 2.5, 'category': 'Oilseed'},\n",
    "        'Safflower': {'pH': (6.0, 7.5), 'P': 20, 'K': 2.0, 'category': 'Oilseed, Drought Tolerant'},\n",
    "        'Coconut': {'pH': (5.5, 7.0), 'P': 25, 'K': 5.0, 'category': 'Perennial, Oil'},\n",
    "        \n",
    "        # Cash Crops\n",
    "        'Cotton': {'pH': (6.0, 7.5), 'P': 20, 'K': 3.0, 'category': 'Cash Crop, High Nutrient'},\n",
    "        'Sugarcane': {'pH': (6.0, 7.5), 'P': 25, 'K': 3.0, 'category': 'Cash Crop, High Yield'},\n",
    "        'Tobacco': {'pH': (5.5, 6.5), 'P': 20, 'K': 3.0, 'category': 'Cash Crop'},\n",
    "        'Jute': {'pH': (5.5, 7.0), 'P': 15, 'K': 2.0, 'category': 'Fiber'},\n",
    "        \n",
    "        # Vegetables\n",
    "        'Tomato': {'pH': (6.0, 7.0), 'P': 25, 'K': 2.5, 'category': 'Vegetable, High Value'},\n",
    "        'Onion': {'pH': (6.0, 7.0), 'P': 25, 'K': 2.5, 'category': 'Vegetable, Bulb'},\n",
    "        'Potato': {'pH': (5.5, 7.0), 'P': 25, 'K': 3.0, 'category': 'Vegetable, Tuber'},\n",
    "        'Cabbage': {'pH': (6.0, 7.5), 'P': 20, 'K': 2.0, 'category': 'Vegetable, Leafy'},\n",
    "        'Cauliflower': {'pH': (6.0, 7.5), 'P': 20, 'K': 2.0, 'category': 'Vegetable, Brassica'},\n",
    "        'Carrot': {'pH': (5.5, 7.0), 'P': 15, 'K': 2.0, 'category': 'Vegetable, Root'},\n",
    "        'Beetroot': {'pH': (6.0, 7.5), 'P': 15, 'K': 2.0, 'category': 'Vegetable, Root'},\n",
    "        'Radish': {'pH': (5.5, 7.0), 'P': 15, 'K': 1.5, 'category': 'Vegetable, Root'},\n",
    "        'Cucumber': {'pH': (5.5, 7.0), 'P': 20, 'K': 2.5, 'category': 'Vegetable, Vine'},\n",
    "        'Brinjal': {'pH': (5.5, 7.0), 'P': 20, 'K': 2.5, 'category': 'Vegetable, Solanaceae'},\n",
    "        'Okra': {'pH': (6.0, 7.5), 'P': 15, 'K': 2.0, 'category': 'Vegetable, High Value'},\n",
    "        'Pumpkin': {'pH': (5.5, 7.5), 'P': 15, 'K': 2.5, 'category': 'Vegetable, Vine'},\n",
    "        'Watermelon': {'pH': (5.5, 7.5), 'P': 15, 'K': 2.5, 'category': 'Vegetable, Vine, Summer'},\n",
    "        'Muskmelon': {'pH': (5.5, 7.5), 'P': 15, 'K': 2.5, 'category': 'Vegetable, Vine, Summer'},\n",
    "        \n",
    "        # Fruits\n",
    "        'Banana': {'pH': (5.5, 7.0), 'P': 30, 'K': 4.0, 'category': 'Fruit, Perennial, High Yield'},\n",
    "        'Mango': {'pH': (5.5, 7.5), 'P': 25, 'K': 3.0, 'category': 'Fruit, Perennial'},\n",
    "        'Citrus': {'pH': (5.5, 7.0), 'P': 25, 'K': 3.0, 'category': 'Fruit, Perennial, Acid Loving'},\n",
    "        'Apple': {'pH': (6.0, 7.5), 'P': 20, 'K': 2.5, 'category': 'Fruit, Temperate'},\n",
    "        'Grape': {'pH': (6.0, 7.5), 'P': 20, 'K': 3.0, 'category': 'Fruit, Perennial, Vine'},\n",
    "        'Papaya': {'pH': (5.5, 7.0), 'P': 25, 'K': 3.0, 'category': 'Fruit, Tropical'},\n",
    "        'Pineapple': {'pH': (5.0, 6.5), 'P': 20, 'K': 2.5, 'category': 'Fruit, Tropical'},\n",
    "        'Strawberry': {'pH': (5.5, 6.5), 'P': 20, 'K': 2.5, 'category': 'Fruit, Berry'},\n",
    "        \n",
    "        # Spices & Condiments\n",
    "        'Turmeric': {'pH': (5.5, 7.0), 'P': 20, 'K': 2.5, 'category': 'Spice, Rhizome'},\n",
    "        'Ginger': {'pH': (5.5, 6.5), 'P': 20, 'K': 2.5, 'category': 'Spice, Rhizome'},\n",
    "        'Garlic': {'pH': (5.5, 7.5), 'P': 25, 'K': 2.5, 'category': 'Spice, Bulb'},\n",
    "        'Chilli': {'pH': (5.5, 7.0), 'P': 20, 'K': 2.5, 'category': 'Spice, High Value'},\n",
    "        'Black Pepper': {'pH': (5.0, 6.5), 'P': 25, 'K': 3.0, 'category': 'Spice, Perennial, Climbing'},\n",
    "        'Coriander': {'pH': (6.0, 7.5), 'P': 15, 'K': 1.5, 'category': 'Spice'},\n",
    "        'Cardamom': {'pH': (5.5, 7.0), 'P': 20, 'K': 2.5, 'category': 'Spice, Shade Loving'},\n",
    "        \n",
    "        # Beverages\n",
    "        'Tea': {'pH': (4.5, 5.5), 'P': 20, 'K': 3.0, 'category': 'Beverage, Acid Loving'},\n",
    "        'Coffee': {'pH': (5.5, 6.5), 'P': 25, 'K': 3.0, 'category': 'Beverage, Shade Loving'},\n",
    "        \n",
    "        # Additional Important Crops\n",
    "        'Tapioca': {'pH': (5.5, 7.0), 'P': 15, 'K': 2.5, 'category': 'Root Crop'},\n",
    "        'Sweet Potato': {'pH': (5.5, 7.0), 'P': 15, 'K': 2.5, 'category': 'Root Crop'},\n",
    "        'Arecanut': {'pH': (5.5, 7.0), 'P': 25, 'K': 3.0, 'category': 'Perennial'},\n",
    "        'Rubber': {'pH': (5.0, 6.5), 'P': 25, 'K': 3.0, 'category': 'Perennial, Acid Loving'},\n",
    "        'Coconut': {'pH': (5.5, 7.0), 'P': 25, 'K': 5.0, 'category': 'Perennial'},\n",
    "        'Peas': {'pH': (6.0, 7.5), 'P': 20, 'K': 2.0, 'category': 'Vegetable Pulse'},\n",
    "        'Bitter Gourd': {'pH': (5.5, 7.0), 'P': 15, 'K': 2.5, 'category': 'Vegetable, Vine'},\n",
    "        'Bottle Gourd': {'pH': (5.5, 7.5), 'P': 15, 'K': 2.5, 'category': 'Vegetable, Vine'},\n",
    "        'Ridge Gourd': {'pH': (5.5, 7.5), 'P': 15, 'K': 2.5, 'category': 'Vegetable, Vine'},\n",
    "        'Ash Gourd': {'pH': (5.5, 7.5), 'P': 15, 'K': 2.5, 'category': 'Vegetable, Vine'},\n",
    "    }\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    # Score each crop based on soil parameters\n",
    "    for crop, requirements in crop_db.items():\n",
    "        ph_min, ph_max = requirements['pH']\n",
    "        req_p = requirements['P']\n",
    "        req_k = requirements['K']\n",
    "        \n",
    "        # Calculate suitability score (0-100)\n",
    "        score = 100\n",
    "        \n",
    "        # pH match (bell curve around optimal)\n",
    "        ph_optimal = (ph_min + ph_max) / 2\n",
    "        ph_diff = abs(pH - ph_optimal)\n",
    "        if ph_diff > 2:\n",
    "            score -= 40\n",
    "        elif ph_diff > 1:\n",
    "            score -= 20\n",
    "        elif ph_diff > 0.5:\n",
    "            score -= 5\n",
    "        \n",
    "        # Nutrient availability match\n",
    "        if exP < req_p * 0.5:\n",
    "            score -= 15\n",
    "        elif exP < req_p:\n",
    "            score -= 5\n",
    "        \n",
    "        if exK < req_k * 0.5:\n",
    "            score -= 15\n",
    "        elif exK < req_k:\n",
    "            score -= 5\n",
    "        \n",
    "        # Organic matter preference\n",
    "        if crop in ['Rice', 'Sugarcane', 'Banana', 'Tomato', 'Onion']:\n",
    "            if OM < 25:\n",
    "                score -= 10\n",
    "        \n",
    "        score = max(0, min(100, score))\n",
    "        \n",
    "        recommendations.append({\n",
    "            'crop': crop,\n",
    "            'score': score,\n",
    "            'category': requirements['category'],\n",
    "            'reason': ''\n",
    "        })\n",
    "    \n",
    "    # Sort by score and return top 15\n",
    "    recommendations = sorted(recommendations, key=lambda x: x['score'], reverse=True)[:15]\n",
    "    \n",
    "    # Generate HTML report\n",
    "    html_crops = \"\"\"\n",
    "    <div style=\"font-family: Arial, sans-serif; line-height: 1.6; color: #333;\">\n",
    "        <h3>ğŸŒ¾ Top 15 Recommended Crops</h3>\n",
    "        <table style=\"width: 100%; border-collapse: collapse;\">\n",
    "            <tr style=\"background: #3498db; color: white;\">\n",
    "                <th style=\"border: 1px solid #ddd; padding: 10px; text-align: left;\">Crop</th>\n",
    "                <th style=\"border: 1px solid #ddd; padding: 10px; text-align: center;\">Suitability</th>\n",
    "                <th style=\"border: 1px solid #ddd; padding: 10px; text-align: left;\">Category</th>\n",
    "            </tr>\n",
    "    \"\"\"\n",
    "    \n",
    "    for rec in recommendations:\n",
    "        if rec['score'] >= 80:\n",
    "            color = '#27ae60'\n",
    "            bar = 'â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ âœ“âœ“âœ“'\n",
    "        elif rec['score'] >= 60:\n",
    "            color = '#3498db'\n",
    "            bar = 'â–ˆâ–ˆâ–ˆâ–ˆ âœ“âœ“'\n",
    "        elif rec['score'] >= 40:\n",
    "            color = '#f39c12'\n",
    "            bar = 'â–ˆâ–ˆâ–ˆ âœ“'\n",
    "        else:\n",
    "            color = '#e74c3c'\n",
    "            bar = 'â–ˆâ–ˆ'\n",
    "        \n",
    "        html_crops += f\"\"\"\n",
    "            <tr>\n",
    "                <td style=\"border: 1px solid #ddd; padding: 10px; font-weight: bold;\">{rec['crop']}</td>\n",
    "                <td style=\"border: 1px solid #ddd; padding: 10px; text-align: center;\">\n",
    "                    <span style=\"color: {color};\">{rec['score']:.0f}%</span>\n",
    "                </td>\n",
    "                <td style=\"border: 1px solid #ddd; padding: 10px;\">{rec['category']}</td>\n",
    "            </tr>\n",
    "        \"\"\"\n",
    "    \n",
    "    html_crops += \"\"\"\n",
    "        </table>\n",
    "        <p style=\"margin-top: 15px; font-size: 12px; color: #666;\">\n",
    "            <strong>Note:</strong> Scores based on soil parameters. Consider climate, market demand, and crop rotation.\n",
    "        </p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    return html_crops\n",
    "\n",
    "\n",
    "def create_soil_health_visualizations(Clay, OM, CEC, pH, V, exP, exK, exCa, exMg):\n",
    "    \"\"\"\n",
    "    Create Plotly visualizations for soil health parameters\n",
    "    - Radar chart with optimal ranges\n",
    "    - Bar chart comparing current vs optimal nutrient levels\n",
    "    \"\"\"\n",
    "    \n",
    "    params = ['Clay', 'OM', 'CEC', 'pH', 'V', 'exP', 'exK', 'exCa', 'exMg']\n",
    "    values = [Clay, OM, CEC, pH, V, exP, exK, exCa, exMg]\n",
    "    \n",
    "    # Normalize to 0-100 scale\n",
    "    max_values = [500, 50, 150, 8, 100, 100, 15, 100, 60]\n",
    "    normalized = [(v / m) * 100 for v, m in zip(values, max_values)]\n",
    "    \n",
    "    # Create radar chart\n",
    "    fig = go.Figure(data=go.Scatterpolar(\n",
    "        r=normalized,\n",
    "        theta=params,\n",
    "        fill='toself',\n",
    "        name='Current Soil',\n",
    "        line=dict(color='#3498db'),\n",
    "        fillcolor='rgba(52, 152, 219, 0.3)'\n",
    "    ))\n",
    "    \n",
    "    # Add optimal range as reference\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=[80] * len(params),\n",
    "        theta=params,\n",
    "        name='Optimal Range',\n",
    "        line=dict(color='#27ae60', dash='dash'),\n",
    "        fillcolor='rgba(39, 174, 96, 0.1)'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        polar=dict(radialaxis=dict(visible=True, range=[0, 100])),\n",
    "        showlegend=True,\n",
    "        title=\"ğŸŒ± Soil Health Radar Chart\",\n",
    "        height=600,\n",
    "        font=dict(size=11)\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "print(\"âœ“ Soil health analysis functions created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_yield_data_for_training(df):\n",
    "    \"\"\"\n",
    "    Prepare data for v6.0 ensemble training\n",
    "    - Engineer features\n",
    "    - Clean data\n",
    "    - Split with stratification\n",
    "    - Handle categorical encoding\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“Š DATA PREPARATION FOR v6.0 ENSEMBLE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Step 1: Engineer features\n",
    "    print(\"\\n  [1/4] Engineering features...\")\n",
    "    df_features = engineer_yield_features(df)\n",
    "    print(f\"        Created {len(df_features.columns) - len(df.columns)} new features\")\n",
    "    \n",
    "    # Step 2: Clean data\n",
    "    print(\"\\n  [2/4] Cleaning data...\")\n",
    "    df_clean = clean_yield_data(df_features)\n",
    "    \n",
    "    # Step 3: Prepare features & target\n",
    "    print(\"\\n  [3/4] Preparing features and target...\")\n",
    "    \n",
    "    # Find target column\n",
    "    target_col = None\n",
    "    for col in ['Production_in_tons', 'Production', 'production']:\n",
    "        if col in df_clean.columns:\n",
    "            target_col = col\n",
    "            break\n",
    "    if target_col is None:\n",
    "        prod_cols = [col for col in df_clean.columns if 'production' in col.lower()]\n",
    "        target_col = prod_cols[0] if prod_cols else None\n",
    "    \n",
    "    if target_col is None:\n",
    "        raise ValueError(\"Cannot find target column\")\n",
    "    \n",
    "    y = df_clean[target_col].values\n",
    "    X = df_clean.drop(columns=[target_col])\n",
    "    crops = X['Crop'].values\n",
    "    \n",
    "    # Identify categorical columns\n",
    "    categorical_cols = [c for c in ['Crop', 'Season', 'State', 'State_Name', 'District', 'Crop_Type'] if c in X.columns]\n",
    "    \n",
    "    # Label encode categorical columns for tree models\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        X[col + '_le'] = le.fit_transform(X[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    print(f\"        Features: {X.shape[1]} columns, {len(categorical_cols)} categorical\")\n",
    "    \n",
    "    # Step 4: Train/test split with stratification\n",
    "    print(\"\\n  [4/4] Stratified train/test split...\")\n",
    "    X_train, X_test, y_train, y_test, crops_train, crops_test = train_test_split(\n",
    "        X, y, crops, test_size=0.2, random_state=42, stratify=X['Crop']\n",
    "    )\n",
    "    print(f\"        Train: {len(X_train):,} | Test: {len(X_test):,}\")\n",
    "    \n",
    "    # Target encoding (fit on train only)\n",
    "    print(\"\\n  Applying target encoding...\")\n",
    "    target_encoder = ce.TargetEncoder(cols=categorical_cols, smoothing=10)\n",
    "    X_train_te = target_encoder.fit_transform(X_train[categorical_cols], y_train)\n",
    "    X_test_te = target_encoder.transform(X_test[categorical_cols])\n",
    "    \n",
    "    # Add target-encoded columns\n",
    "    for col in categorical_cols:\n",
    "        X_train[col + '_te'] = X_train_te[col].values\n",
    "        X_test[col + '_te'] = X_test_te[col].values\n",
    "    \n",
    "    # Select only numeric columns\n",
    "    X_train_final = X_train.select_dtypes(include=[np.number]).copy()\n",
    "    X_test_final = X_test.select_dtypes(include=[np.number]).copy()\n",
    "    \n",
    "    # Clean column names\n",
    "    X_train_final.columns = X_train_final.columns.str.replace('[^A-Za-z0-9_]', '_', regex=True)\n",
    "    X_test_final.columns = X_test_final.columns.str.replace('[^A-Za-z0-9_]', '_', regex=True)\n",
    "    \n",
    "    # Scaling for MLP\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_final)\n",
    "    X_test_scaled = scaler.transform(X_test_final)\n",
    "    \n",
    "    print(f\"        Final feature count: {X_train_final.shape[1]}\")\n",
    "    print(\"\\nâœ… Data preparation complete!\")\n",
    "    \n",
    "    return {\n",
    "        'X_train': X_train_final,\n",
    "        'X_test': X_test_final,\n",
    "        'X_train_scaled': X_train_scaled,\n",
    "        'X_test_scaled': X_test_scaled,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'crops_train': crops_train,\n",
    "        'crops_test': crops_test,\n",
    "        'scaler': scaler,\n",
    "        'target_encoder': target_encoder,\n",
    "        'label_encoders': label_encoders,\n",
    "        'feature_names': X_train_final.columns.tolist()\n",
    "    }\n",
    "\n",
    "\n",
    "def train_crop_yield_ensemble_v6(df):\n",
    "    \"\"\"\n",
    "    Train v6.0 ensemble with 6 base models + Ridge meta-learner\n",
    "    - XGBoost, LightGBM, CatBoost, RandomForest, GradientBoosting, MLP\n",
    "    - Out-of-fold (OOF) predictions for meta-learner\n",
    "    - Early stopping with proper cross-validation\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ¤– TRAINING v6.0 ENSEMBLE (6 Models + Ridge Meta-Learner)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Prepare data\n",
    "    data = prepare_yield_data_for_training(df)\n",
    "    X_train = data['X_train']\n",
    "    X_test = data['X_test']\n",
    "    X_train_scaled = data['X_train_scaled']\n",
    "    X_test_scaled = data['X_test_scaled']\n",
    "    y_train = data['y_train']\n",
    "    y_test = data['y_test']\n",
    "    \n",
    "    # Early stopping subset (last 10% of training data)\n",
    "    es_split = int(len(X_train) * 0.9)\n",
    "    X_tr = X_train.iloc[:es_split]\n",
    "    X_es = X_train.iloc[es_split:]\n",
    "    y_tr = y_train[:es_split]\n",
    "    y_es = y_train[es_split:]\n",
    "    X_tr_scaled = X_train_scaled[:es_split]\n",
    "    X_es_scaled = X_train_scaled[es_split:]\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # Train base models\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    print(\"\\n  Training base models with early stopping...\")\n",
    "    \n",
    "    print(\"    [1/6] XGBoost...\", end=\" \", flush=True)\n",
    "    xgb_model = XGBRegressor(\n",
    "        n_estimators=2000, max_depth=6, learning_rate=0.03,\n",
    "        subsample=0.75, colsample_bytree=0.7,\n",
    "        min_child_weight=5, gamma=0.2,\n",
    "        reg_alpha=0.8, reg_lambda=1.5,\n",
    "        random_state=42, n_jobs=-1, tree_method='hist',\n",
    "        early_stopping_rounds=50, eval_metric='mae'\n",
    "    )\n",
    "    xgb_model.fit(X_tr, y_tr, eval_set=[(X_es, y_es)], verbose=False)\n",
    "    print(f\"âœ“ (iter {xgb_model.best_iteration})\")\n",
    "    \n",
    "    print(\"    [2/6] LightGBM...\", end=\" \", flush=True)\n",
    "    lgb_model = LGBMRegressor(\n",
    "        n_estimators=2000, max_depth=7, learning_rate=0.025,\n",
    "        subsample=0.8, colsample_bytree=0.65,\n",
    "        min_child_samples=30, reg_alpha=0.5, reg_lambda=2.0,\n",
    "        random_state=42, n_jobs=-1, verbose=-1\n",
    "    )\n",
    "    lgb_model.fit(X_tr, y_tr,\n",
    "                  eval_set=[(X_es, y_es)],\n",
    "                  callbacks=[lgb_lib.callback.early_stopping(50, verbose=False),\n",
    "                             lgb_lib.callback.log_evaluation(0)])\n",
    "    print(f\"âœ“ (iter {lgb_model.best_iteration_})\")\n",
    "    \n",
    "    print(\"    [3/6] CatBoost...\", end=\" \", flush=True)\n",
    "    cat_model = CatBoostRegressor(\n",
    "        iterations=2000, learning_rate=0.03, depth=5,\n",
    "        l2_leaf_reg=5, random_seed=42,\n",
    "        early_stopping_rounds=50, verbose=0\n",
    "    )\n",
    "    cat_model.fit(X_tr, y_tr, eval_set=(X_es, y_es))\n",
    "    print(f\"âœ“ (iter {cat_model.best_iteration_})\")\n",
    "    \n",
    "    print(\"    [4/6] RandomForest...\", end=\" \", flush=True)\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=500, max_depth=18, min_samples_split=5,\n",
    "        min_samples_leaf=3, max_features='sqrt',\n",
    "        random_state=42, n_jobs=-1\n",
    "    )\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    print(\"âœ“\")\n",
    "    \n",
    "    print(\"    [5/6] GradientBoosting...\", end=\" \", flush=True)\n",
    "    gb_model = GradientBoostingRegressor(\n",
    "        n_estimators=500, learning_rate=0.03, max_depth=5,\n",
    "        min_samples_split=8, min_samples_leaf=4,\n",
    "        subsample=0.75, random_state=42\n",
    "    )\n",
    "    gb_model.fit(X_train, y_train)\n",
    "    print(\"âœ“\")\n",
    "    \n",
    "    print(\"    [6/6] MLP...\", end=\" \", flush=True)\n",
    "    mlp_model = MLPRegressor(\n",
    "        hidden_layer_sizes=(128, 64),\n",
    "        activation='relu', alpha=0.01,\n",
    "        learning_rate='adaptive', learning_rate_init=0.001,\n",
    "        max_iter=800, early_stopping=True, validation_fraction=0.1,\n",
    "        n_iter_no_change=30, random_state=42\n",
    "    )\n",
    "    mlp_model.fit(X_tr_scaled, y_tr)\n",
    "    print(\"âœ“\")\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # Generate base predictions for meta-learner\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    print(\"\\n  Generating base predictions for meta-learner...\")\n",
    "    \n",
    "    base_preds_train = np.column_stack([\n",
    "        xgb_model.predict(X_train),\n",
    "        lgb_model.predict(X_train),\n",
    "        cat_model.predict(X_train),\n",
    "        rf_model.predict(X_train),\n",
    "        gb_model.predict(X_train),\n",
    "        mlp_model.predict(X_train_scaled)\n",
    "    ])\n",
    "    \n",
    "    base_preds_test = np.column_stack([\n",
    "        xgb_model.predict(X_test),\n",
    "        lgb_model.predict(X_test),\n",
    "        cat_model.predict(X_test),\n",
    "        rf_model.predict(X_test),\n",
    "        gb_model.predict(X_test),\n",
    "        mlp_model.predict(X_test_scaled)\n",
    "    ])\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # Train Ridge meta-learner\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    print(\"\\n  Training Ridge meta-learner on base predictions...\")\n",
    "    meta_model = Ridge(alpha=1.0, fit_intercept=True)\n",
    "    meta_model.fit(base_preds_train, y_train)\n",
    "    \n",
    "    # Evaluate meta-learner\n",
    "    meta_preds_train = meta_model.predict(base_preds_train)\n",
    "    oof_mae = mean_absolute_error(y_train, meta_preds_train)\n",
    "    oof_pct = np.median(np.abs((y_train - meta_preds_train) / y_train) * 100)\n",
    "    print(f\"    Training MAE: {oof_mae:.4f}  |  Median %Error: {oof_pct:.2f}%\")\n",
    "    \n",
    "    print(\"\\n  Meta-learner coefficients (weight per base model):\")\n",
    "    model_names = ['XGB', 'LGB', 'CAT', 'RF', 'GB', 'MLP']\n",
    "    for name, coef in zip(model_names, meta_model.coef_):\n",
    "        print(f\"    {name:>4s}: {coef:.4f}\")\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # Final test evaluation\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“Š FINAL TEST EVALUATION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    y_pred = meta_model.predict(base_preds_test)\n",
    "    y_pred = np.clip(y_pred, 0, None)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    pct_err = np.abs((y_test - y_pred) / y_test) * 100\n",
    "    median_err = np.median(pct_err)\n",
    "    \n",
    "    w5 = (pct_err <= 5).mean() * 100\n",
    "    w10 = (pct_err <= 10).mean() * 100\n",
    "    w15 = (pct_err <= 15).mean() * 100\n",
    "    w20 = (pct_err <= 20).mean() * 100\n",
    "    w25 = (pct_err <= 25).mean() * 100\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ Regression Metrics:\")\n",
    "    print(f\"  RÂ²   = {r2:.4f}\")\n",
    "    print(f\"  MAE  = {mae:.3f} ton/ha\")\n",
    "    print(f\"  RMSE = {rmse:.3f} ton/ha\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Error Distribution:\")\n",
    "    print(f\"  Median %Error = {median_err:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Accuracy Bands:\")\n",
    "    print(f\"  Within  5%: {w5:5.1f}%\")\n",
    "    print(f\"  Within 10%: {w10:5.1f}%\")\n",
    "    print(f\"  Within 15%: {w15:5.1f}%\")\n",
    "    print(f\"  Within 20%: {w20:5.1f}%\")\n",
    "    print(f\"  Within 25%: {w25:5.1f}%\")\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # Save all models\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    print(\"\\nğŸ’¾ Saving models...\")\n",
    "    models_dir = os.path.join(os.getcwd(), \"models\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    models_to_save = {\n",
    "        'xgb_model.pkl': xgb_model,\n",
    "        'lgb_model.pkl': lgb_model,\n",
    "        'cat_model.pkl': cat_model,\n",
    "        'rf_model.pkl': rf_model,\n",
    "        'gb_model.pkl': gb_model,\n",
    "        'mlp_model.pkl': mlp_model,\n",
    "        'meta_model.pkl': meta_model,\n",
    "        'scaler.pkl': data['scaler'],\n",
    "        'target_encoder.pkl': data['target_encoder'],\n",
    "        'label_encoders.pkl': data['label_encoders']\n",
    "    }\n",
    "    \n",
    "    for filename, model in models_to_save.items():\n",
    "        with open(os.path.join(models_dir, filename), 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'model_type': 'Ensemble v6.0',\n",
    "        'base_models': model_names,\n",
    "        'meta_learner': 'Ridge',\n",
    "        'test_r2': float(r2),\n",
    "        'test_mae': float(mae),\n",
    "        'test_median_error_pct': float(median_err),\n",
    "        'accuracy_within_20pct': float(w20),\n",
    "        'feature_names': data['feature_names'],\n",
    "        'feature_count': len(data['feature_names'])\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(models_dir, 'ensemble_metadata.json'), 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"  âœ“ Saved to {models_dir}/\")\n",
    "    \n",
    "    print(\"\\nâœ… v6.0 Ensemble training complete!\")\n",
    "    \n",
    "    return {\n",
    "        'models': {\n",
    "            'xgb': xgb_model,\n",
    "            'lgb': lgb_model,\n",
    "            'cat': cat_model,\n",
    "            'rf': rf_model,\n",
    "            'gb': gb_model,\n",
    "            'mlp': mlp_model,\n",
    "            'meta': meta_model\n",
    "        },\n",
    "        'scaler': data['scaler'],\n",
    "        'data': data,\n",
    "        'metrics': {\n",
    "            'r2': r2,\n",
    "            'mae': mae,\n",
    "            'median_error': median_err\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def predict_crop_yield_v6(N, P, K, pH, rainfall, temperature, Area_in_hectares, State_Name, Crop_Type, Crop):\n",
    "    \"\"\"\n",
    "    Predict crop yield using v6.0 ensemble\n",
    "    \"\"\"\n",
    "    try:\n",
    "        models_dir = os.path.join(os.getcwd(), \"models\")\n",
    "        \n",
    "        # Load all models\n",
    "        with open(os.path.join(models_dir, 'xgb_model.pkl'), 'rb') as f:\n",
    "            xgb_model = pickle.load(f)\n",
    "        with open(os.path.join(models_dir, 'lgb_model.pkl'), 'rb') as f:\n",
    "            lgb_model = pickle.load(f)\n",
    "        with open(os.path.join(models_dir, 'cat_model.pkl'), 'rb') as f:\n",
    "            cat_model = pickle.load(f)\n",
    "        with open(os.path.join(models_dir, 'rf_model.pkl'), 'rb') as f:\n",
    "            rf_model = pickle.load(f)\n",
    "        with open(os.path.join(models_dir, 'gb_model.pkl'), 'rb') as f:\n",
    "            gb_model = pickle.load(f)\n",
    "        with open(os.path.join(models_dir, 'mlp_model.pkl'), 'rb') as f:\n",
    "            mlp_model = pickle.load(f)\n",
    "        with open(os.path.join(models_dir, 'meta_model.pkl'), 'rb') as f:\n",
    "            meta_model = pickle.load(f)\n",
    "        with open(os.path.join(models_dir, 'scaler.pkl'), 'rb') as f:\n",
    "            scaler = pickle.load(f)\n",
    "        with open(os.path.join(models_dir, 'label_encoders.pkl'), 'rb') as f:\n",
    "            label_encoders = pickle.load(f)\n",
    "        \n",
    "        # Create input dataframe\n",
    "        input_data = pd.DataFrame({\n",
    "            'N': [N],\n",
    "            'P': [P],\n",
    "            'K': [K],\n",
    "            'pH': [pH],\n",
    "            'rainfall': [rainfall],\n",
    "            'temperature': [temperature],\n",
    "            'Area_in_hectares': [Area_in_hectares],\n",
    "            'State_Name': [State_Name.lower()],\n",
    "            'Crop_Type': [Crop_Type.lower()],\n",
    "            'Crop': [Crop.lower()]\n",
    "        })\n",
    "        \n",
    "        # Engineer features (same as training)\n",
    "        input_features = engineer_yield_features(input_data)\n",
    "        \n",
    "        # Encode categorical variables\n",
    "        for col in ['State_Name', 'Crop_Type', 'Crop']:\n",
    "            if col in label_encoders:\n",
    "                try:\n",
    "                    input_features[col + '_le'] = label_encoders[col].transform(input_features[col].astype(str))\n",
    "                except:\n",
    "                    input_features[col + '_le'] = 0\n",
    "        \n",
    "        # Select numeric columns and scale for MLP\n",
    "        input_numeric = input_features.select_dtypes(include=[np.number]).copy()\n",
    "        input_numeric.columns = input_numeric.columns.str.replace('[^A-Za-z0-9_]', '_', regex=True)\n",
    "        input_scaled = scaler.transform(input_numeric)\n",
    "        \n",
    "        # Get predictions from all base models\n",
    "        base_preds = np.column_stack([\n",
    "            xgb_model.predict(input_numeric),\n",
    "            lgb_model.predict(input_numeric),\n",
    "            cat_model.predict(input_numeric),\n",
    "            rf_model.predict(input_numeric),\n",
    "            gb_model.predict(input_numeric),\n",
    "            mlp_model.predict(input_scaled)\n",
    "        ])\n",
    "        \n",
    "        # Final prediction from meta-learner\n",
    "        production = meta_model.predict(base_preds)[0]\n",
    "        production = max(0, production)\n",
    "        yield_per_hectare = production / Area_in_hectares if Area_in_hectares > 0 else 0\n",
    "        \n",
    "        result = f\"\"\"## Crop Yield Prediction (v6.0 Ensemble)\n",
    "\n",
    "### Input Parameters:\n",
    "- **Crop:** {Crop.title()}\n",
    "- **Crop Type:** {Crop_Type.title()}\n",
    "- **State:** {State_Name.title()}\n",
    "- **Area:** {Area_in_hectares} hectares\n",
    "\n",
    "### Soil & Climate:\n",
    "- N: {N} kg/ha | P: {P} kg/ha | K: {K} kg/ha\n",
    "- pH: {pH} | Temperature: {temperature}Â°C | Rainfall: {rainfall} mm\n",
    "\n",
    "### Predictions:\n",
    "- **Total Production:** {production:.2f} tons\n",
    "- **Yield per Hectare:** {yield_per_hectare:.2f} tons/hectare\n",
    "\n",
    "### Recommendations:\n",
    "{f\"âœ“ Excellent yield - maintain current practices\" if yield_per_hectare > 2.5 else f\"âœ“ Good yield - continue current management\" if yield_per_hectare > 2.0 else f\"âš  Moderate yield - consider improving nutrients/irrigation\" if yield_per_hectare > 1.5 else f\"âŒ Low yield - need significant improvements in soil/water management\"}\n",
    "\"\"\"\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error in prediction: {str(e)}\\n\\nMake sure to train the ensemble first by running the training cell.\"\n",
    "\n",
    "\n",
    "# Train the v6.0 ensemble\n",
    "print(\"\\nğŸš€ Training v6.0 Ensemble...\")\n",
    "ensemble_results = train_crop_yield_ensemble_v6(crop_yield_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contnets of final/crop_yield.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contnets of final/crop_disease.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contnets of final/soil_health.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# ğŸŒ¾ AI-Powered Agricultural Assistant\")\n",
    "    \n",
    "    with gr.Tabs():\n",
    "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        # TAB 1: Crop Recommendation\n",
    "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        with gr.Tab(\"ğŸŒ± Crop Recommendation\"):\n",
    "            gr.Markdown(\"### Recommend best crops based on soil nutrients, temperature, and rainfall\")\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    nitrogen = gr.Slider(0, 140, value=50, label=\"Nitrogen (N)\")\n",
    "                    phosphorus = gr.Slider(5, 145, value=50, label=\"Phosphorus (P)\")\n",
    "                    potassium = gr.Slider(5, 205, value=50, label=\"Potassium (K)\")\n",
    "                    ph = gr.Slider(3.5, 9.5, value=6.5, step=0.1, label=\"pH Value\")\n",
    "                with gr.Column():\n",
    "                    temperature = gr.Slider(8, 45, value=25, step=0.5, label=\"Temperature (Â°C)\")\n",
    "                    humidity = gr.Slider(14, 100, value=70, step=1, label=\"Humidity (%)\")\n",
    "                    rainfall = gr.Slider(20, 300, value=100, step=5, label=\"Rainfall (mm)\")\n",
    "            recommend_btn = gr.Button(\"Get Crop Recommendation\", variant=\"primary\")\n",
    "            crop_output = gr.Markdown()\n",
    "            recommend_btn.click(fn=predict_crop_recommendation, inputs=[nitrogen, phosphorus, potassium, temperature, humidity, ph, rainfall], outputs=crop_output)\n",
    "        \n",
    "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        # TAB 2: Disease Detection\n",
    "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        with gr.Tab(\"ğŸ”¬ Disease Detection\"):\n",
    "            gr.Markdown(\"### Detect plant diseases using image analysis\")\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    disease_image = gr.Image(type=\"pil\", label=\"Upload Plant Image\")\n",
    "                    crop_type_disease = gr.Dropdown(choices=[\"Tomato\", \"Potato\", \"Pepper\", \"Apple\", \"Corn\", \"Grape\", \"Strawberry\"], value=\"Tomato\", label=\"Crop Type\")\n",
    "                    detect_btn = gr.Button(\"Detect Disease\", variant=\"primary\")\n",
    "                with gr.Column():\n",
    "                    disease_output = gr.Markdown()\n",
    "            detect_btn.click(fn=detect_plant_disease, inputs=[disease_image, crop_type_disease], outputs=disease_output)\n",
    "        \n",
    "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        # TAB 3: Market Price Analysis\n",
    "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        with gr.Tab(\"ğŸ’° Market Price Analysis\"):\n",
    "            gr.Markdown(\"### Analyze commodity prices and market trends\")\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    unique_commodities = sorted(market_price_df['Commodity'].unique()[:50])\n",
    "                    unique_states = sorted(market_price_df['State'].unique())\n",
    "                    commodity_input = gr.Dropdown(choices=unique_commodities, value=unique_commodities[0] if unique_commodities else \"Rice\", label=\"Commodity\", allow_custom_value=True)\n",
    "                    state_input = gr.Dropdown(choices=unique_states, value=unique_states[0] if unique_states else \"Punjab\", label=\"State\")\n",
    "                    date_range = gr.Slider(7, 90, value=30, step=1, label=\"Analysis Period (days)\")\n",
    "                    analyze_btn = gr.Button(\"Analyze Prices\", variant=\"primary\")\n",
    "                with gr.Column():\n",
    "                    price_output = gr.Markdown()\n",
    "            price_plot = gr.Image()\n",
    "            analyze_btn.click(fn=analyze_market_prices, inputs=[commodity_input, state_input, date_range], outputs=[price_output, price_plot])\n",
    "        \n",
    "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        # TAB 4: Crop Yield Prediction (v6.0 Ensemble)\n",
    "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        with gr.Tab(\"ğŸ“Š Crop Yield Prediction\"):\n",
    "            gr.Markdown(\"### Predict crop yield using advanced v6.0 ensemble model\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    yield_N = gr.Slider(0, 140, value=80, label=\"Nitrogen (N) kg/ha\")\n",
    "                    yield_P = gr.Slider(5, 145, value=40, label=\"Phosphorus (P) kg/ha\")\n",
    "                    yield_K = gr.Slider(5, 205, value=40, label=\"Potassium (K) kg/ha\")\n",
    "                    yield_pH = gr.Slider(3.5, 9.5, value=6.5, step=0.1, label=\"pH Value\")\n",
    "                \n",
    "                with gr.Column():\n",
    "                    yield_rainfall = gr.Slider(20, 3500, value=200, step=10, label=\"Rainfall (mm)\")\n",
    "                    yield_temp = gr.Slider(8, 45, value=25, step=0.5, label=\"Temperature (Â°C)\")\n",
    "                    yield_area = gr.Slider(0.1, 100000, value=100, step=0.1, label=\"Area (hectares)\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    yield_state = gr.Dropdown(\n",
    "                        choices=['Andaman and Nicobar Islands', 'Andhra Pradesh', 'Arunachal Pradesh', \n",
    "                                'Assam', 'Bihar', 'Chandigarh', 'Chhattisgarh', 'Goa', 'Gujarat', \n",
    "                                'Haryana', 'Himachal Pradesh', 'Jammu and Kashmir', 'Jharkhand', \n",
    "                                'Karnataka', 'Kerala', 'Madhya Pradesh', 'Maharashtra', 'Manipur', \n",
    "                                'Meghalaya', 'Mizoram', 'Nagaland', 'Odisha', 'Puducherry', 'Punjab', \n",
    "                                'Rajasthan', 'Sikkim', 'Tamil Nadu', 'Telangana', 'Tripura', \n",
    "                                'Uttar Pradesh', 'Uttarakhand', 'West Bengal'],\n",
    "                        value='Punjab',\n",
    "                        label=\"State\"\n",
    "                    )\n",
    "                    yield_crop_type = gr.Dropdown(\n",
    "                        choices=['Kharif', 'Rabi', 'Whole Year', 'Summer'],\n",
    "                        value='Kharif',\n",
    "                        label=\"Crop Type (Season)\"\n",
    "                    )\n",
    "                \n",
    "                with gr.Column():\n",
    "                    yield_crop = gr.Dropdown(\n",
    "                        choices=['Rice', 'Wheat', 'Maize', 'Cotton', 'Sugarcane', 'Potato', \n",
    "                                'Tomato', 'Onion', 'Banana', 'Mango', 'Apple', 'Grapes', \n",
    "                                'Soyabean', 'Sunflower', 'Groundnut'],\n",
    "                        value='Rice',\n",
    "                        label=\"Crop\",\n",
    "                        allow_custom_value=True\n",
    "                    )\n",
    "            \n",
    "            predict_yield_btn = gr.Button(\"Predict Crop Yield\", variant=\"primary\")\n",
    "            yield_output = gr.Markdown()\n",
    "            \n",
    "            predict_yield_btn.click(\n",
    "                fn=predict_crop_yield_v6,\n",
    "                inputs=[yield_N, yield_P, yield_K, yield_pH, yield_rainfall, \n",
    "                       yield_temp, yield_area, yield_state, yield_crop_type, yield_crop],\n",
    "                outputs=yield_output\n",
    "            )\n",
    "        \n",
    "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        # TAB 5: Soil Health Analysis (NEW)\n",
    "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        with gr.Tab(\"ğŸŒ± Soil Health Analysis\"):\n",
    "            gr.Markdown(\"### Comprehensive soil health assessment with crop recommendations\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    soil_clay = gr.Slider(100, 600, value=350, step=10, label=\"Clay (g/kg)\")\n",
    "                    soil_om = gr.Slider(10, 50, value=25, step=1, label=\"Organic Matter (g/kg)\")\n",
    "                    soil_cec = gr.Slider(30, 150, value=80, step=5, label=\"CEC (cmolâ‚Š/kg)\")\n",
    "                    soil_pH = gr.Slider(4.0, 8.0, value=5.5, step=0.1, label=\"pH\")\n",
    "                    soil_V = gr.Slider(20, 100, value=65, step=5, label=\"Base Saturation (%)\")\n",
    "                \n",
    "                with gr.Column():\n",
    "                    soil_exP = gr.Slider(5, 100, value=20, step=5, label=\"Available P (mg/kg)\")\n",
    "                    soil_exK = gr.Slider(0.5, 15, value=3.0, step=0.5, label=\"Available K (mg/kg)\")\n",
    "                    soil_exCa = gr.Slider(10, 100, value=35, step=5, label=\"Available Ca (mg/kg)\")\n",
    "                    soil_exMg = gr.Slider(5, 60, value=18, step=2, label=\"Available Mg (mg/kg)\")\n",
    "            \n",
    "            analyze_soil_btn = gr.Button(\"Analyze Soil Health\", variant=\"primary\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Tabs():\n",
    "                    with gr.TabItem(\"ğŸ“‹ Health Report\"):\n",
    "                        soil_health_report = gr.HTML()\n",
    "                    \n",
    "                    with gr.TabItem(\"ğŸŒ¾ Crop Recommendations\"):\n",
    "                        soil_crop_recs = gr.HTML()\n",
    "                    \n",
    "                    with gr.TabItem(\"ğŸ“ˆ Visualizations\"):\n",
    "                        soil_radar_chart = gr.Plot()\n",
    "            \n",
    "            def analyze_soil_and_display(clay, om, cec, pH, V, exP, exK, exCa, exMg):\n",
    "                health_html, score, status, color = analyze_soil_health(clay, om, cec, pH, V, exP, exK, exCa, exMg)\n",
    "                crop_html = get_crop_recommendations_for_soil(clay, om, cec, pH, V, exP, exK, exCa, exMg)\n",
    "                viz = create_soil_health_visualizations(clay, om, cec, pH, V, exP, exK, exCa, exMg)\n",
    "                return health_html, crop_html, viz\n",
    "            \n",
    "            analyze_soil_btn.click(\n",
    "                fn=analyze_soil_and_display,\n",
    "                inputs=[soil_clay, soil_om, soil_cec, soil_pH, soil_V, soil_exP, soil_exK, soil_exCa, soil_exMg],\n",
    "                outputs=[soil_health_report, soil_crop_recs, soil_radar_chart]\n",
    "            )\n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "KisaanSathi_Project",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 412860,
     "sourceId": 790184,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 635203,
     "sourceId": 1129180,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1046158,
     "sourceId": 1760012,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3146821,
     "sourceId": 5441978,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3489366,
     "sourceId": 6305205,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
